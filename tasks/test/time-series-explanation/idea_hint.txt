Proposed two metrics, Cumulative Prediction Difference and Cumulative Prediction Preservation, which compute sequential differences between the model’s class-probability vectors as points are removed in descending or ascending order of absolute attribution, respectively; larger differences indicate greater faithfulness for the former and smaller differences for the latter. Building on Integrated Gradients, you should replace the all-zero baseline with a partially retained baseline defined by a binary mask, producing intermediate points α(M ⊙ x) + (1 − M) ⊙ x that keep some values intact to mitigate out-of-distribution paths while probing disrupted temporal relationships. Attributions are computed conditionally on masked points and aggregated via an expectation over random masks, estimating per-point contributions under varied contexts. To align with temporal structure, apply masking to contiguous segments rather than independent points; a generator picks n segments with lengths in [s_min, s_max], and the final attribution should be the expectation of the masked Integrated Gradients over such segment-based masks. A cost-efficient variant could randomize the mask along the integration path and uses a single sample to approximate the inner expectation, supported by a bounded-gradient argument that allows interchanging expectation and integration. The method should preserve sensitivity and implementation invariance properties of Integrated Gradients but, by design, does not guarantee completeness since it integrates over multiple baseline contexts.